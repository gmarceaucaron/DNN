<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.9.1"/>
<title>DNN: nn_ops_conv.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">DNN
   &#160;<span id="projectnumber">1.0</span>
   </div>
   <div id="projectbrief">Lightweight library in C for training riemannian neural networks</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.9.1 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">nn_ops_conv.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="nn__ops__conv_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/***************************************************************************************</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">Copyright (October 26 2015)</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment">Authors:</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">  Gaétan Marceau Caron (INRIA-Saclay)</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">  gaetan.marceau-caron@inria.fr</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">  Yann Olliver (CNRS &amp; Paris-Saclay University)</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">  yann.ollivier@lri.fr</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">  This work has been partially funded by the French cooperative project TIMCO, Pôle de Compétitivité Systematic (FUI 13).</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"></span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">  This software is a computer program whose purpose is to provide an experimental framework</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">  for research in Deep Learning and Riemannian optimization. </span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">  This software is governed by the CeCILL license under French law and</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">  abiding by the rules of distribution of free software.  You can  use,</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment">  modify and/ or redistribute the software under the terms of the CeCILL</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">  license as circulated by CEA, CNRS and INRIA at the following URL</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">  &quot;http://www.cecill.info&quot;.</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="comment">  As a counterpart to the access to the source code and  rights to copy,</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="comment">  modify and redistribute granted by the license, users are provided only</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="comment">  with a limited warranty  and the software&#39;s author,  the holder of the</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="comment">  economic rights,  and the successive licensors  have only  limited</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">  liability.</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="comment">  In this respect, the user&#39;s attention is drawn to the risks associated</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="comment">  with loading,  using,  modifying and/or developing or reproducing the</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="comment">  software by the user in light of its specific status of free software,</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">  that may mean  that it is complicated to manipulate,  and  that  also</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="comment">  therefore means  that it is reserved for developers  and  experienced</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="comment">  professionals having in-depth computer knowledge. Users are therefore</span></div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">  encouraged to load and test the software&#39;s suitability as regards their</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="comment">  requirements in conditions enabling the security of their systems and/or</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="comment">  data to be ensured and,  more generally, to use and operate it in the</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="comment">  same conditions as regards security.</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="comment">  </span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="comment">  The fact that you are presently reading this means that you have had</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="comment">  knowledge of the CeCILL license and that you accept its terms.</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">**************************************************************************************/</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="utils_8hpp.html">utils.hpp</a>&quot;</span></div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;<span class="preprocessor">#include &quot;utils_conv.hpp&quot;</span></div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="nn__ops_8hpp.html">nn_ops.hpp</a>&quot;</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;</div>
<div class="line"><a name="l00063"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a2d1a1a57b9ab6fcf73dac5906c9abd04">   63</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#a2d1a1a57b9ab6fcf73dac5906c9abd04">transposeConvW</a>(<span class="keyword">const</span> MyMatrix&amp; conv_W,</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;                    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_chan,</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;                    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> Hf,</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;                    MyMatrix &amp;conv_W_T){</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_filter = conv_W.rows();</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    conv_W_T.setZero(n_chan, Hf*Hf*n_filter);</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; n_filter; i++){</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> j = 0; j &lt; conv_W.cols(); j++){</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> idx1 = j/(Hf*Hf);</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> idx2 = (Hf*Hf-j%(Hf*Hf)-1)+i*Hf*Hf;</div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;            conv_W_T(idx1,idx2) = conv_W(i,j);</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        }</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    }</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;}</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;</div>
<div class="line"><a name="l00088"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a9e8b09d7012b01113c26ff54bd026cd9">   88</a></span>&#160;<span class="keywordtype">unsigned</span> <a class="code" href="nn__ops__conv_8hpp.html#a9e8b09d7012b01113c26ff54bd026cd9">initConvLayer</a>(<span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;                       std::vector&lt;MyMatrix&gt; &amp;convW,</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                       std::vector&lt;MyMatrix&gt; &amp;convW_T,</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                       std::vector&lt;MyVector&gt; &amp;convB){</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    </div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    std::default_random_engine generator;</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    std::normal_distribution&lt;double&gt; distribution(0.0,0.01); <span class="comment">//@TODO parametrize the noise amplitude</span></div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    <span class="keywordtype">unsigned</span> n_params = 0;</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> l = 0; l &lt; conv_params.size(); l++){</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_filter = conv_params[l].n_filter;</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> Hf = conv_params[l].Hf;</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        <span class="keywordtype">unsigned</span> n_channel = N_CHANNEL;</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        <span class="keywordflow">if</span>(l&gt;0){</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;            n_channel = conv_params[l-1].n_filter;</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        }</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        convW[l].resize(n_filter, Hf*Hf*n_channel);</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;        convB[l].resize(n_filter);</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; n_filter; i++){</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;            convB[l](i) = distribution(generator);</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> j = 0; j &lt; n_channel; j++){</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> ko = 0; ko &lt; Hf; ko++){</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> ki = 0; ki &lt; Hf; ki++){</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                        convW[l](i,j*Hf*Hf+ko*Hf+ki) = distribution(generator);</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                        n_params++;</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;                    }</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;                }</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;            }</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        }</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;        <a class="code" href="nn__ops__conv_8hpp.html#a2d1a1a57b9ab6fcf73dac5906c9abd04">transposeConvW</a>(convW[l],n_channel, Hf,convW_T[l]);</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    }</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="keywordflow">return</span> n_params;</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;}</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;</div>
<div class="line"><a name="l00136"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#af007d6a69bc2da9b8497eaa771eb1e51">  136</a></span>&#160;<span class="keywordtype">int</span> <a class="code" href="nn__ops__conv_8hpp.html#af007d6a69bc2da9b8497eaa771eb1e51">initNetwork</a>(<span class="keyword">const</span> std::vector&lt;unsigned&gt; &amp;nn_arch, </div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;                <span class="keyword">const</span> std::string act_func, </div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;                <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;                <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;W,</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;                std::vector&lt;MyVector&gt; &amp;B,</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;convW,</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;convW_T,</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;                std::vector&lt;MyVector&gt; &amp;convB){</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;  </div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="comment">// Fix some parameters</span></div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_layers = nn_arch.size();</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;    <span class="keywordtype">double</span> sigma = 1.0;</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    <span class="keywordflow">if</span>(act_func==<span class="stringliteral">&quot;sigmoid&quot;</span>){</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;        sigma = 4.0;</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    }</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    <span class="keywordtype">unsigned</span> param_counter = 0;</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;</div>
<div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;    <span class="comment">// Initialize the convolutional layer</span></div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    param_counter += <a class="code" href="nn__ops__conv_8hpp.html#a9e8b09d7012b01113c26ff54bd026cd9">initConvLayer</a>(conv_params, convW, convW_T, convB);</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;  </div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <span class="comment">// Initialize the weights</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; n_layers-1; i++){</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        <a class="code" href="nn__ops_8hpp.html#a90b8525c0edded9e3420dc56dbb9332f">initWeight</a>(nn_arch[i], nn_arch[i+1], sigma, W[i]);</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        <span class="keywordflow">if</span>(act_func==<span class="stringliteral">&quot;sigmoid&quot;</span>){</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;            B[i] = -0.5 * W[i].colwise().sum();</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        }<span class="keywordflow">else</span> <span class="keywordflow">if</span>(act_func==<span class="stringliteral">&quot;tanh&quot;</span>){</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;            B[i] = MyVector::Zero(W[i].cols());</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        }<span class="keywordflow">else</span> <span class="keywordflow">if</span>(act_func==<span class="stringliteral">&quot;relu&quot;</span>){ <span class="comment">// TODO: find the right way to initialize relu</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;            B[i] = MyVector::Zero(W[i].cols());</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;        }<span class="keywordflow">else</span>{</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;            std::cout &lt;&lt; <span class="stringliteral">&quot;Not implemented!&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;            assert(<span class="keyword">false</span>);</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        }</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        param_counter += nn_arch[i] * nn_arch[i+1] + nn_arch[i+1];</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;    }</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    <span class="keywordflow">return</span> param_counter;</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;}</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;</div>
<div class="line"><a name="l00189"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a1fce4d87ddb93dde916eeafd9e724f59">  189</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#a1fce4d87ddb93dde916eeafd9e724f59">poolMax</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_img,</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;             <span class="keyword">const</span> <span class="keywordtype">unsigned</span> conv_N1,</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;             <span class="keyword">const</span> <span class="keywordtype">unsigned</span> conv_N2,</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;             <span class="keyword">const</span> <span class="keywordtype">unsigned</span> F,</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;             <span class="keyword">const</span> <span class="keywordtype">unsigned</span> S,</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;             <span class="keyword">const</span> MyMatrix&amp; conv_layer,</div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;             MyMatrix&amp; pool_layer,</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;             std::vector&lt;unsigned&gt; &amp;pool_idx_x,</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;             std::vector&lt;unsigned&gt; &amp;pool_idx_y){</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> conv_depth = conv_layer.rows();</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;    pool_layer.resize(conv_depth, conv_N2*conv_N2*n_img);</div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;  </div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; n_img; i++){</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> j = 0; j &lt; conv_depth; j++){</div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;            <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> no = 0; no &lt; conv_N2; no++){</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;                <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> ni = 0; ni &lt; conv_N2; ni++){</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;                    <span class="keywordtype">double</span> max_val = -1.0e20;</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;                    <span class="keywordtype">unsigned</span> max_idx = -1;</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;                    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> ko = 0; ko &lt; F; ko++){</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                        <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> ki = 0; ki &lt; F; ki++){</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;                            <span class="keyword">const</span> <span class="keywordtype">unsigned</span> idx = ki + ko * conv_N1 + ni * S + no * S * conv_N1 + i*conv_N1*conv_N1;</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                            <span class="keywordflow">if</span>(conv_layer(j,idx) &gt; max_val){</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;                                max_val = conv_layer(j,idx);</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                                max_idx = idx;</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                            }</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;                        }</div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                    }</div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;                    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> idx2 = i*conv_N2*conv_N2+no*conv_N2+ni;</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;                    pool_layer(j,idx2) = max_val;</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;                    pool_idx_x.push_back(j);</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;                    pool_idx_y.push_back(max_idx);</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;                }</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;            }</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;        }</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    }</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;}</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;</div>
<div class="line"><a name="l00244"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#ab863f7d41b9e0d9d104779c802c60b4d">  244</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#ab863f7d41b9e0d9d104779c802c60b4d">convFprop</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;               <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;               <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;               <span class="keyword">const</span> ActivationFunction &amp;act_func,</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_W, </div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyVector&gt; &amp;conv_B,</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;X_batch,</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;               std::vector&lt;MyMatrix&gt; &amp;conv_A,</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;               std::vector&lt;MyMatrix&gt; &amp;conv_Ap,</div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;               MyMatrix&amp; z0,</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;               std::vector&lt;std::vector&lt;unsigned&gt;&gt; &amp;poolIdxX,</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;               std::vector&lt;std::vector&lt;unsigned&gt;&gt; &amp;poolIdxY){</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;    <span class="keyword">const</span> MyMatrix* Atilde = &amp;X_batch;</div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;    MyMatrix pool_z0;</div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; conv_W.size(); i++){</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        MyMatrix conv_z0 = conv_W[i] * *Atilde;</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;        conv_z0.colwise() += conv_B[i];</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;</div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        MyMatrix conv_a(conv_z0.rows(), conv_z0.cols());;</div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        conv_Ap[i].resize(conv_z0.rows(), conv_z0.cols());</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;        act_func(conv_z0,conv_a,conv_Ap[i]);</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;  </div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;        <span class="comment">// Pool max for conv layer</span></div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;        <a class="code" href="nn__ops__conv_8hpp.html#a1fce4d87ddb93dde916eeafd9e724f59">poolMax</a>(batch_size, conv_params[i].N, pool_params[i].N, pool_params[i].Hf, pool_params[i].stride, conv_a, pool_z0, poolIdxX[i], poolIdxY[i]);</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;    </div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;        <span class="keywordflow">if</span>(i &lt; conv_W.size()-1){</div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;            buildConvMatrix(batch_size, pool_params[i].N, conv_params[i+1].N, conv_params[i+1].Hf, conv_params[i+1].stride, conv_params[i+1].padding, pool_z0, conv_A[i]);</div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;            Atilde = &amp;conv_A[i];</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;        }</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    }</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;    <span class="comment">// Convert the pool layer into a FNN layer</span></div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;    conv2Layer(batch_size, pool_params[conv_W.size()-1].N, pool_z0, z0);</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;}</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;</div>
<div class="line"><a name="l00295"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a86d5271f3402baee41e3e757fa2327a2">  295</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#a86d5271f3402baee41e3e757fa2327a2">convBprop</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;               <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;               <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;convW_T,</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;convAp,</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;pool_gradB,</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;               std::vector&lt;MyMatrix&gt; &amp;gradB,</div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;               std::vector&lt;std::vector&lt;unsigned&gt;&gt; &amp;poolIdxX,</div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;               std::vector&lt;std::vector&lt;unsigned&gt;&gt; &amp;poolIdxY){</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;  </div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;    <span class="keyword">const</span> MyMatrix* Atilde = &amp;pool_gradB;</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;  </div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_layers = convW_T.size();</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> l = 0; l &lt; n_layers; l++){</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    </div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> rev_l = n_layers - l - 1;</div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;    </div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;        MyMatrix conv_gradB_act;</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;</div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;        <span class="keywordtype">double</span> prev_time = gettime();</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;        pool2conv(batch_size, conv_params[rev_l].n_filter, conv_params[rev_l].N, pool_params[rev_l].N, poolIdxX[rev_l], poolIdxY[rev_l], *const_cast&lt;MyMatrix *&gt;(Atilde), conv_gradB_act);</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;</div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;        prev_time = gettime();</div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;        gradB[rev_l] = conv_gradB_act.cwiseProduct(convAp[rev_l]);</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;    </div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;        <span class="keywordflow">if</span>(rev_l&gt;0){</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;            MyMatrix conv_mat_pool;</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;            prev_time = gettime();</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;            buildConvMatrix(batch_size, conv_params[rev_l].N, pool_params[rev_l-1].N, conv_params[rev_l].Hf, conv_params[rev_l].stride, pool_params[rev_l-1].N-conv_params[rev_l].N, gradB[rev_l], conv_mat_pool);</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;            *<span class="keyword">const_cast&lt;</span>MyMatrix *<span class="keyword">&gt;</span>(Atilde) = convW_T[rev_l] * conv_mat_pool;</div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;        }</div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    }</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;}</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;</div>
<div class="line"><a name="l00343"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#ac8b3063f74f3e00895c31d569c68aaa2">  343</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#ac8b3063f74f3e00895c31d569c68aaa2">convUpdate</a>(<span class="keyword">const</span> <span class="keywordtype">double</span> eta,</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;                <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_gradB, </div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;                <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_A, </div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;                <span class="keyword">const</span> MyMatrix &amp;X_batch,</div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                <span class="keyword">const</span> std::string regularizer,</div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">double</span> lambda,</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                std::vector&lt;MyVector&gt; &amp;conv_B){</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> l = 0; l &lt; conv_W.size(); l++){</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;        <span class="keyword">const</span> MyMatrix* Atilde = &amp;X_batch;</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        <span class="keywordflow">if</span>(l &gt; 0){</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;            Atilde = &amp;conv_A[l-1];</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;        }</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;        MyMatrix conv_update = conv_gradB[l] * Atilde-&gt;transpose();</div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;        conv_W[l] -= eta * conv_update;</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;        conv_B[l] -= eta * conv_update.rowwise().sum();</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;    }</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;}</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;</div>
<div class="line"><a name="l00377"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a2d211cd2f6f6acab9da2c708d3cce3f2">  377</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#ac8b3063f74f3e00895c31d569c68aaa2">convUpdate</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">double</span> eta,</div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;                <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;                <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_gradB, </div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;                <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_A, </div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;                <span class="keyword">const</span> MyMatrix &amp;X_batch,</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;                <span class="keyword">const</span> std::string regularizer,</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                <span class="keyword">const</span> <span class="keywordtype">double</span> lambda,</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;                std::vector&lt;MyMatrix&gt; &amp;conv_W_T,</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;                std::vector&lt;MyVector&gt; &amp;conv_B){</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> l = 0; l &lt; conv_W.size(); l++){</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;        <span class="keyword">const</span> MyMatrix* Atilde = &amp;X_batch;</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;        <span class="keywordflow">if</span>(l &gt; 0){</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;            Atilde = &amp;conv_A[l-1];</div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;        }</div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;        MyMatrix conv_update = conv_gradB[l] * Atilde-&gt;transpose();</div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;        conv_W[l] -= eta * conv_update / batch_size;</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;        <span class="keyword">const</span> <span class="keywordtype">unsigned</span> Hf = conv_params[l].Hf;</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;        <span class="keywordtype">unsigned</span> n_channel = N_CHANNEL;</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;        <span class="keywordflow">if</span>(l&gt;0){</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;            n_channel = conv_params[l-1].n_filter;</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;        }</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        <a class="code" href="nn__ops__conv_8hpp.html#a2d1a1a57b9ab6fcf73dac5906c9abd04">transposeConvW</a>(conv_W[l],n_channel, Hf,conv_W_T[l]);</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;        conv_B[l] -= eta * conv_gradB[l].rowwise().sum() / batch_size;</div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    }</div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;}</div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;</div>
<div class="line"><a name="l00422"></a><span class="lineno"><a class="line" href="nn__ops__conv_8hpp.html#a9eac26b0f319ddcafb904deca1c8a416">  422</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops__conv_8hpp.html#a9eac26b0f319ddcafb904deca1c8a416">convUpdateTest</a>(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;                    <span class="keyword">const</span> <span class="keywordtype">double</span> eta,</div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;                    <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_gradB, </div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;                    <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_A, </div>
<div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;                    <span class="keyword">const</span> MyMatrix &amp;X_batch,</div>
<div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;                    <span class="keyword">const</span> std::string regularizer,</div>
<div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                    <span class="keyword">const</span> <span class="keywordtype">double</span> lambda,</div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;                    std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                    std::vector&lt;MyVector&gt; &amp;conv_B,</div>
<div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;                    std::vector&lt;MyMatrix&gt; &amp;conv_update,</div>
<div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;                    std::vector&lt;MyVector&gt; &amp;conv_updateB){</div>
<div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;  </div>
<div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> l = 0; l &lt; conv_W.size(); l++){</div>
<div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;        <span class="keyword">const</span> MyMatrix* Atilde = &amp;X_batch;</div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;        <span class="keywordflow">if</span>(l &gt; 0){</div>
<div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;            Atilde = &amp;conv_A[l-1];</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;        }</div>
<div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;</div>
<div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;        conv_update[l] = (conv_gradB[l] * Atilde-&gt;transpose())/batch_size;</div>
<div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;        conv_updateB[l] = conv_gradB[l].rowwise().sum()/batch_size;</div>
<div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;    }</div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;}</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;</div>
<div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="keywordtype">void</span> updateConvMetric(<span class="keyword">const</span> <span class="keywordtype">bool</span> init_flag,</div>
<div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;                      <span class="keyword">const</span> <span class="keywordtype">double</span> gamma,</div>
<div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;                      std::vector&lt;MyMatrix&gt; &amp;conv_Mii,</div>
<div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;                      std::vector&lt;MyMatrix&gt; &amp;conv_M0i,</div>
<div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;                      std::vector&lt;MyVector&gt; &amp;conv_M00,</div>
<div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;                      std::vector&lt;MyMatrix&gt; &amp;conv_pMii,</div>
<div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;                      std::vector&lt;MyMatrix&gt; &amp;conv_pM0i,</div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;                      std::vector&lt;MyVector&gt; &amp;conv_pM00){</div>
<div class="line"><a name="l00453"></a><span class="lineno">  453</span>&#160;    <span class="keywordflow">if</span>(!init_flag){</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;        <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> k = 0; k &lt; conv_Mii.size(); k++){</div>
<div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;            conv_Mii[k] = (1.0 - gamma) * conv_pMii[k]  + gamma * conv_Mii[k];</div>
<div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;            conv_M0i[k] = (1.0 - gamma) * conv_pM0i[k]  + gamma * conv_M0i[k];</div>
<div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;            conv_M00[k] = (1.0 - gamma) * conv_pM00[k]  + gamma * conv_M00[k];</div>
<div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;        }</div>
<div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;    }</div>
<div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;    conv_pMii = conv_Mii;</div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    conv_pM0i = conv_M0i;</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;    conv_pM00 = conv_M00;</div>
<div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;}</div>
<div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;</div>
<div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;<span class="keywordtype">void</span> buildConvQDMetric(<span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;                       <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_gradB_sq,</div>
<div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;                       <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_A,</div>
<div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;                       <span class="keyword">const</span> MyMatrix &amp;X_batch,</div>
<div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;                       <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_W, </div>
<div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                       <span class="keyword">const</span> <span class="keywordtype">double</span> mat_reg,</div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;                       std::vector&lt;MyMatrix&gt; &amp;conv_Mii,</div>
<div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;                       std::vector&lt;MyMatrix&gt; &amp;conv_M0i,</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;                       std::vector&lt;MyVector&gt; &amp;conv_M00){</div>
<div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;</div>
<div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;    <span class="keyword">const</span> MyMatrix* Atilde = &amp;X_batch;  </div>
<div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; conv_Mii.size(); i++){</div>
<div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;        <span class="keyword">const</span> MyMatrix A_sq = Atilde-&gt;array().square();</div>
<div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;        conv_Mii[i] =  conv_gradB_sq[i] * A_sq.transpose() / batch_size;</div>
<div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;        conv_Mii[i].array() += mat_reg;</div>
<div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;        conv_M0i[i] = conv_gradB_sq[i] * Atilde-&gt;transpose() / batch_size;</div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;        conv_M00[i] = conv_gradB_sq[i].rowwise().sum() / batch_size;</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;        conv_M00[i].array() += mat_reg;</div>
<div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;</div>
<div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;        Atilde = &amp;conv_A[i];</div>
<div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;</div>
<div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;    }</div>
<div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;}</div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;</div>
<div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops_8hpp.html#a9a994e746ada8c2bd3f11b68114db234">computeLoss</a>(<span class="keyword">const</span> ActivationFunction &amp;act_func,</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;                 <span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;                 <span class="keyword">const</span> MyMatrix &amp;X,</div>
<div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;                 <span class="keyword">const</span> MyVector &amp;Y,</div>
<div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;                 <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;                 <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;                 <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;                 <span class="keyword">const</span> std::vector&lt;MyVector&gt; &amp;conv_B,</div>
<div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;                 <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;W, </div>
<div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;                 <span class="keyword">const</span> std::vector&lt;MyVector&gt; &amp;B,</div>
<div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;                 <span class="keywordtype">double</span> &amp;loss,</div>
<div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;                 <span class="keywordtype">double</span> &amp;accuracy){</div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;    <span class="keyword">const</span> MyMatrix* Atilde = &amp;X;</div>
<div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;  </div>
<div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;    MyMatrix pool_z0;</div>
<div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;    MyMatrix conv_A;</div>
<div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; conv_W.size(); i++){</div>
<div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;    </div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;        MyMatrix conv_z0 = conv_W[i] * *Atilde;</div>
<div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;        conv_z0.colwise() += conv_B[i];</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    </div>
<div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;        MyMatrix conv_act(conv_z0.rows(), conv_z0.cols());</div>
<div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;        MyMatrix conv_ap(conv_z0.rows(), conv_z0.cols());</div>
<div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;    </div>
<div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;        act_func(conv_z0,conv_act,conv_ap);</div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    </div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;        <span class="comment">// Pool max for conv layer</span></div>
<div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;        std::vector&lt;unsigned&gt; pool_idx_x;</div>
<div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;        std::vector&lt;unsigned&gt; pool_idx_y;</div>
<div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;        <a class="code" href="nn__ops__conv_8hpp.html#a1fce4d87ddb93dde916eeafd9e724f59">poolMax</a>(batch_size, conv_params[i].N, pool_params[i].N, pool_params[i].Hf, pool_params[i].stride, conv_act, pool_z0, pool_idx_x, pool_idx_y);</div>
<div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;    </div>
<div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;        <span class="keywordflow">if</span>(i &lt; conv_W.size()-1){</div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;            buildConvMatrix(batch_size, pool_params[i].N, conv_params[i+1].N, conv_params[i+1].Hf, conv_params[i+1].stride, conv_params[i+1].padding, pool_z0, conv_A);</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;            Atilde = &amp;conv_A;</div>
<div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;        }</div>
<div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;    }</div>
<div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;  </div>
<div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;    <span class="comment">// Convert the pool layer into a FNN layer</span></div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;    MyMatrix z0;</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;    conv2Layer(batch_size, pool_params[conv_W.size()-1].N, pool_z0, z0);</div>
<div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;  </div>
<div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_layers = W.size() + 1;</div>
<div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;</div>
<div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;    MyMatrix z = (z0 * W[0]).rowwise() + B[0].transpose();</div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;    MyMatrix a(z.rows(), z.cols());    </div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;    MyMatrix ap(z.rows(), z.cols());</div>
<div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;    act_func(z, a, ap);</div>
<div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;</div>
<div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 1; i &lt; W.size()-1; i++){</div>
<div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;        z = (a * W[i]).rowwise() + B[i].transpose();</div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;        a.resize(z.rows(), z.cols());</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;        ap.resize(z.rows(), z.cols());</div>
<div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;</div>
<div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;        act_func(z, a, ap); <span class="comment">// TODO: replace without the computation of the derivative</span></div>
<div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;    }</div>
<div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;  </div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;    a = (a*W[W.size()-1]).rowwise() + B[W.size()-1].transpose();</div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;</div>
<div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;    MyMatrix out;</div>
<div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;    <a class="code" href="nn__ops_8hpp.html#a4c86f2557fe76d7b0ca7c5111eb7927b">softmax</a>(a, out);</div>
<div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;  </div>
<div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;    <span class="keywordtype">double</span> cum_loss = 0.;</div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; out.rows(); i++){</div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;        <span class="keywordflow">if</span>(out(i,Y(i)) &gt; 1e-6){</div>
<div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;            cum_loss += -1. * log(out(i,Y(i)));</div>
<div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;        }<span class="keywordflow">else</span>{</div>
<div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;            cum_loss += 15.0;</div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;        }</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;    }</div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;</div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;    <span class="comment">// Compute the accuracy</span></div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;    <span class="keywordtype">unsigned</span> n_correct = 0;</div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> i = 0; i &lt; out.rows(); i++){</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;        MyMatrix::Index idx;</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;        <span class="keywordtype">double</span> val = out.row(i).maxCoeff(&amp;idx);</div>
<div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;        <span class="keywordflow">if</span>(idx==Y(i))</div>
<div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;            n_correct++;</div>
<div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;    }</div>
<div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;    <span class="comment">// accuracy = (float)n_correct/out.rows();</span></div>
<div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;    <span class="comment">// loss = cum_loss/out.rows();</span></div>
<div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;    accuracy = (float)n_correct;</div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;    loss = cum_loss;</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;  </div>
<div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;}</div>
<div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;</div>
<div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops_8hpp.html#a99cafbd2955aafe43ad57a88f7f1db5c">evalModel</a>(<span class="keyword">const</span> ActivationFunction &amp;eval_act_func,</div>
<div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;               <span class="keyword">const</span> <a class="code" href="struct_params.html">Params</a> &amp;params,</div>
<div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;               <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_batch,</div>
<div class="line"><a name="l00578"></a><span class="lineno">  578</span>&#160;               <span class="keyword">const</span> <span class="keywordtype">unsigned</span> batch_size,</div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;               <span class="keyword">const</span> <span class="keywordtype">unsigned</span> n_example,</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;X,</div>
<div class="line"><a name="l00581"></a><span class="lineno">  581</span>&#160;               <span class="keyword">const</span> MyVector &amp;Y,</div>
<div class="line"><a name="l00582"></a><span class="lineno">  582</span>&#160;               <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00583"></a><span class="lineno">  583</span>&#160;               <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyVector&gt; &amp;conv_B,</div>
<div class="line"><a name="l00586"></a><span class="lineno">  586</span>&#160;               std::vector&lt;MyMatrix&gt; &amp;W_eval,</div>
<div class="line"><a name="l00587"></a><span class="lineno">  587</span>&#160;               std::vector&lt;MyVector&gt; &amp;B,</div>
<div class="line"><a name="l00588"></a><span class="lineno">  588</span>&#160;               <span class="keywordtype">double</span> &amp;acc_loss,</div>
<div class="line"><a name="l00589"></a><span class="lineno">  589</span>&#160;               <span class="keywordtype">double</span> &amp;acc_accuracy){    </div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;</div>
<div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160;    acc_loss = 0.;</div>
<div class="line"><a name="l00592"></a><span class="lineno">  592</span>&#160;    acc_accuracy = 0.;</div>
<div class="line"><a name="l00593"></a><span class="lineno">  593</span>&#160;  </div>
<div class="line"><a name="l00594"></a><span class="lineno">  594</span>&#160;    <span class="comment">// Training accuracy</span></div>
<div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;    <span class="keywordflow">for</span>(<span class="keywordtype">unsigned</span> j = 0; j &lt; n_batch; j++){</div>
<div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;    </div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;        <span class="comment">// Mini-batch creation</span></div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;        <span class="keywordtype">unsigned</span> curr_batch_size = 0;</div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;        MyMatrix X_batch;</div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;        MyVector Y_batch;</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;        getMiniBatch(j, batch_size, X, Y, params, conv_params[0], curr_batch_size, X_batch, Y_batch);</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;    </div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;        <span class="keywordtype">double</span> loss = 0.;</div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160;        <span class="keywordtype">double</span> accuracy = 0.;</div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;        <a class="code" href="nn__ops_8hpp.html#a9a994e746ada8c2bd3f11b68114db234">computeLoss</a>(eval_act_func, curr_batch_size, X_batch, Y_batch, conv_params, pool_params, conv_W, conv_B, W_eval, B, loss, accuracy);</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160;        acc_loss += loss;</div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;        acc_accuracy += accuracy;</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;    }</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;  </div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;    acc_loss/=n_example;</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160;    acc_accuracy/=n_example;</div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;}</div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;<span class="keywordtype">void</span> <a class="code" href="nn__ops_8hpp.html#a99cafbd2955aafe43ad57a88f7f1db5c">evalModel</a>(<span class="keyword">const</span> ActivationFunction &amp;eval_act_func,</div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;               <span class="keyword">const</span> <span class="keywordtype">unsigned</span> train_batch_size,</div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;X_train,</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;Y_train,</div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;               <span class="keyword">const</span> <span class="keywordtype">unsigned</span> valid_batch_size,</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;X_valid,</div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;               <span class="keyword">const</span> MyMatrix &amp;Y_valid,</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;               <span class="keyword">const</span> std::vector&lt;ConvLayerParams&gt; &amp;conv_params,</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;               <span class="keyword">const</span> std::vector&lt;PoolLayerParams&gt; &amp;pool_params,</div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyMatrix&gt; &amp;conv_W,</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;               <span class="keyword">const</span> std::vector&lt;MyVector&gt; &amp;conv_B,</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160;               std::vector&lt;MyMatrix&gt; &amp;W_eval,</div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;               std::vector&lt;MyVector&gt; &amp;B,</div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;               <span class="keywordtype">double</span> &amp;train_loss,</div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;               <span class="keywordtype">double</span> &amp;train_accuracy,</div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;               <span class="keywordtype">double</span> &amp;valid_loss,</div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;               <span class="keywordtype">double</span> &amp;valid_accuracy){</div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;    </div>
<div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;    <span class="comment">// Training accuracy </span></div>
<div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;    <a class="code" href="nn__ops_8hpp.html#a9a994e746ada8c2bd3f11b68114db234">computeLoss</a>(eval_act_func, train_batch_size, X_train, Y_train, conv_params, pool_params, conv_W, conv_B, W_eval, B, train_loss, train_accuracy);</div>
<div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;  </div>
<div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;    <span class="comment">// Validation accuracy</span></div>
<div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;    <a class="code" href="nn__ops_8hpp.html#a9a994e746ada8c2bd3f11b68114db234">computeLoss</a>(eval_act_func, valid_batch_size, X_valid, Y_valid, conv_params, pool_params, conv_W, conv_B, W_eval, B, valid_loss, valid_accuracy);</div>
<div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;</div>
<div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;}</div>
<div class="ttc" id="nn__ops_8hpp_html"><div class="ttname"><a href="nn__ops_8hpp.html">nn_ops.hpp</a></div><div class="ttdoc">Implementation of the functions required for neural networks. </div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_af007d6a69bc2da9b8497eaa771eb1e51"><div class="ttname"><a href="nn__ops__conv_8hpp.html#af007d6a69bc2da9b8497eaa771eb1e51">initNetwork</a></div><div class="ttdeci">int initNetwork(const std::vector&lt; unsigned &gt; &amp;nn_arch, const std::string act_func, const std::vector&lt; ConvLayerParams &gt; &amp;conv_params, const std::vector&lt; PoolLayerParams &gt; &amp;pool_params, std::vector&lt; MyMatrix &gt; &amp;W, std::vector&lt; MyVector &gt; &amp;B, std::vector&lt; MyMatrix &gt; &amp;convW, std::vector&lt; MyMatrix &gt; &amp;convW_T, std::vector&lt; MyVector &gt; &amp;convB)</div><div class="ttdoc">Initialize the parameters of the convolutional Neural Network computational graph. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:136</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_a9e8b09d7012b01113c26ff54bd026cd9"><div class="ttname"><a href="nn__ops__conv_8hpp.html#a9e8b09d7012b01113c26ff54bd026cd9">initConvLayer</a></div><div class="ttdeci">unsigned initConvLayer(const std::vector&lt; ConvLayerParams &gt; &amp;conv_params, std::vector&lt; MyMatrix &gt; &amp;convW, std::vector&lt; MyMatrix &gt; &amp;convW_T, std::vector&lt; MyVector &gt; &amp;convB)</div><div class="ttdoc">Initialize the weights of a convolutional layer with a small normal noise (0.01) </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:88</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_a1fce4d87ddb93dde916eeafd9e724f59"><div class="ttname"><a href="nn__ops__conv_8hpp.html#a1fce4d87ddb93dde916eeafd9e724f59">poolMax</a></div><div class="ttdeci">void poolMax(const unsigned n_img, const unsigned conv_N1, const unsigned conv_N2, const unsigned F, const unsigned S, const MyMatrix &amp;conv_layer, MyMatrix &amp;pool_layer, std::vector&lt; unsigned &gt; &amp;pool_idx_x, std::vector&lt; unsigned &gt; &amp;pool_idx_y)</div><div class="ttdoc">Perform a max pooling operation. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:189</div></div>
<div class="ttc" id="utils_8hpp_html"><div class="ttname"><a href="utils_8hpp.html">utils.hpp</a></div><div class="ttdoc">Implementation of auxiliary functions required for dataset loading and outputting. </div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_a9eac26b0f319ddcafb904deca1c8a416"><div class="ttname"><a href="nn__ops__conv_8hpp.html#a9eac26b0f319ddcafb904deca1c8a416">convUpdateTest</a></div><div class="ttdeci">void convUpdateTest(const unsigned batch_size, const double eta, const std::vector&lt; MyMatrix &gt; &amp;conv_gradB, const std::vector&lt; MyMatrix &gt; &amp;conv_A, const MyMatrix &amp;X_batch, const std::string regularizer, const double lambda, std::vector&lt; MyMatrix &gt; &amp;conv_W, std::vector&lt; MyVector &gt; &amp;conv_B, std::vector&lt; MyMatrix &gt; &amp;conv_update, std::vector&lt; MyVector &gt; &amp;conv_updateB)</div><div class="ttdoc">Implementation of the update function of the convolution layers. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:422</div></div>
<div class="ttc" id="nn__ops_8hpp_html_a9a994e746ada8c2bd3f11b68114db234"><div class="ttname"><a href="nn__ops_8hpp.html#a9a994e746ada8c2bd3f11b68114db234">computeLoss</a></div><div class="ttdeci">void computeLoss(const ActivationFunction &amp;act_func, const MyMatrix &amp;X, const MyVector &amp;Y, const std::vector&lt; MyMatrix &gt; &amp;W, const std::vector&lt; MyVector &gt; &amp;B, double &amp;loss, double &amp;accuracy)</div><div class="ttdoc">function that compute the Negative Log-likelihood and the accuracy of the model </div><div class="ttdef"><b>Definition:</b> nn_ops.hpp:575</div></div>
<div class="ttc" id="struct_params_html"><div class="ttname"><a href="struct_params.html">Params</a></div><div class="ttdef"><b>Definition:</b> utils.hpp:97</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_ac8b3063f74f3e00895c31d569c68aaa2"><div class="ttname"><a href="nn__ops__conv_8hpp.html#ac8b3063f74f3e00895c31d569c68aaa2">convUpdate</a></div><div class="ttdeci">void convUpdate(const double eta, const std::vector&lt; MyMatrix &gt; &amp;conv_gradB, const std::vector&lt; MyMatrix &gt; &amp;conv_A, const MyMatrix &amp;X_batch, const std::string regularizer, const double lambda, std::vector&lt; MyMatrix &gt; &amp;conv_W, std::vector&lt; MyVector &gt; &amp;conv_B)</div><div class="ttdoc">Implementation of the update function of the convolution layers (required for testing) ...</div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:343</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_a2d1a1a57b9ab6fcf73dac5906c9abd04"><div class="ttname"><a href="nn__ops__conv_8hpp.html#a2d1a1a57b9ab6fcf73dac5906c9abd04">transposeConvW</a></div><div class="ttdeci">void transposeConvW(const MyMatrix &amp;conv_W, const unsigned n_chan, const unsigned Hf, MyMatrix &amp;conv_W_T)</div><div class="ttdoc">Transpose the convolution weights according to the characteristic of the filter. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:63</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_a86d5271f3402baee41e3e757fa2327a2"><div class="ttname"><a href="nn__ops__conv_8hpp.html#a86d5271f3402baee41e3e757fa2327a2">convBprop</a></div><div class="ttdeci">void convBprop(const unsigned batch_size, const std::vector&lt; ConvLayerParams &gt; &amp;conv_params, const std::vector&lt; PoolLayerParams &gt; &amp;pool_params, const std::vector&lt; MyMatrix &gt; &amp;convW_T, const std::vector&lt; MyMatrix &gt; &amp;convAp, const MyMatrix &amp;pool_gradB, std::vector&lt; MyMatrix &gt; &amp;gradB, std::vector&lt; std::vector&lt; unsigned &gt;&gt; &amp;poolIdxX, std::vector&lt; std::vector&lt; unsigned &gt;&gt; &amp;poolIdxY)</div><div class="ttdoc">Implementation of the backpropagation algorithm for convolutional layer. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:295</div></div>
<div class="ttc" id="nn__ops__conv_8hpp_html_ab863f7d41b9e0d9d104779c802c60b4d"><div class="ttname"><a href="nn__ops__conv_8hpp.html#ab863f7d41b9e0d9d104779c802c60b4d">convFprop</a></div><div class="ttdeci">void convFprop(const unsigned batch_size, const std::vector&lt; ConvLayerParams &gt; &amp;conv_params, const std::vector&lt; PoolLayerParams &gt; &amp;pool_params, const ActivationFunction &amp;act_func, const std::vector&lt; MyMatrix &gt; &amp;conv_W, const std::vector&lt; MyVector &gt; &amp;conv_B, const MyMatrix &amp;X_batch, std::vector&lt; MyMatrix &gt; &amp;conv_A, std::vector&lt; MyMatrix &gt; &amp;conv_Ap, MyMatrix &amp;z0, std::vector&lt; std::vector&lt; unsigned &gt;&gt; &amp;poolIdxX, std::vector&lt; std::vector&lt; unsigned &gt;&gt; &amp;poolIdxY)</div><div class="ttdoc">Implementation of the forward propagation algorithm for convolutional layer. </div><div class="ttdef"><b>Definition:</b> nn_ops_conv.hpp:244</div></div>
<div class="ttc" id="nn__ops_8hpp_html_a99cafbd2955aafe43ad57a88f7f1db5c"><div class="ttname"><a href="nn__ops_8hpp.html#a99cafbd2955aafe43ad57a88f7f1db5c">evalModel</a></div><div class="ttdeci">void evalModel(const ActivationFunction &amp;eval_act_func, const MyMatrix &amp;X_train, const MyMatrix &amp;Y_train, const MyMatrix &amp;X_valid, const MyMatrix &amp;Y_valid, const Params &amp;params, std::vector&lt; MyMatrix &gt; W_eval, std::vector&lt; MyVector &gt; B, double &amp;train_loss, double &amp;train_accuracy, double &amp;valid_loss, double &amp;valid_accuracy)</div><div class="ttdoc">function that evaluate the model on the training dataset and the validation dataset ...</div><div class="ttdef"><b>Definition:</b> nn_ops.hpp:698</div></div>
<div class="ttc" id="nn__ops_8hpp_html_a4c86f2557fe76d7b0ca7c5111eb7927b"><div class="ttname"><a href="nn__ops_8hpp.html#a4c86f2557fe76d7b0ca7c5111eb7927b">softmax</a></div><div class="ttdeci">void softmax(const MyMatrix &amp;a, MyMatrix &amp;out)</div><div class="ttdoc">Implementation of the softmax function Take a matrix (n_example X n_class) of values and return a mat...</div><div class="ttdef"><b>Definition:</b> nn_ops.hpp:180</div></div>
<div class="ttc" id="nn__ops_8hpp_html_a90b8525c0edded9e3420dc56dbb9332f"><div class="ttname"><a href="nn__ops_8hpp.html#a90b8525c0edded9e3420dc56dbb9332f">initWeight</a></div><div class="ttdeci">void initWeight(const unsigned n_act0, const unsigned n_act1, const double sigma, MyMatrix &amp;W)</div><div class="ttdoc">Initialize the weights of a layer with a reweighted normal noise. </div><div class="ttdef"><b>Definition:</b> nn_ops.hpp:67</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Tue Oct 27 2015 14:23:59 for DNN by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.9.1
</small></address>
</body>
</html>
